---
title: 'Minería de datos: PEC2 - Métodos no supervisados'
author: "Autor: Alberto Perez"
date: "Marzo 2022"
output:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

# Introducción

------------------------------------------------------------------------

## Presentación

Esta Prueba de Evaluación Continuada (PEC) cubre principalmente el módulo de generación de modelos no supervisados del programa de la asignatura.

## Objetivos

En esta PEC trabajaremos la generación, interpretación y evaluación de un modelo de agregación *k-means* y otro *DBSCAN*. Para ello, no perderemos de vista las fases de preparación de los datos, calidad del modelo y extracción inicial del conocimiento.

## Descripción de la PEC a realizar

## Recursos Básicos

**Material docente proporcionado por la UOC.**

Módulo Métodos no supervisados del material didáctico.

## Criterios de valoración

**Ejercicios teóricos**

Todos los ejercicios deben ser presentados de forma razonada y clara, especificando todos y cada uno de los pasos que se hayan llevado a cabo para su resolución. No se aceptará ninguna respuesta que no esté claramente justificada.

**Ejercicios prácticos**

Para todas las PEC es necesario documentar en cada apartado del ejercicio práctico que se ha hecho y cómo se ha hecho.

## Formato y fecha de entrega

El formato de entrega es: **usernameestudiant-PECn.html (pdf o word) y rmd**

Se debe entregar la PEC en el buzón de entregas del aula

## Nota: Propiedad intelectual

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica.

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en qué se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar dónde se obtuvo y su estatus legal: si la obra está protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). El estudiante deberá asegurarse de que la licencia no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra está protegida por copyright.

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.

------------------------------------------------------------------------

# Ejercicios

Los ejercicios se realizarán en base al juego de datos *Hawks* presente en el paquete R *Stat2Data*.

Los estudiantes y el profesorado del Cornell College en Mount Vernon, Iowa, recogieron datos durante muchos años en el mirador de halcones del lago MacBride, cerca de Iowa City, en el estado de Iowa. El conjunto de datos que analizamos aquí es un subconjunto del conjunto de datos original, utilizando sólo aquellas especies para las que había más de 10 observaciones. Los datos se recogieron en muestras aleatorias de tres especies diferentes de halcones: Colirrojo, Gavilán y Halcón de Cooper.

Hemos seleccionado este juego de datos por su parecido con el juego de datos *penguins* y por su potencial a la hora de aplicarle algoritmos de minería de datos no supervisados. Las variables numéricas en las que os basaréis son: *Wing*, *Weight*, *Culmen*, *Hallux*

```{r message= FALSE, warning=FALSE}
if (!require('Stat2Data')) install.packages('Stat2Data')
library(Stat2Data)
data("Hawks")
summary(Hawks)
```

## Ejercicio 1

Presenta el juego de datos, nombre y significado de cada columna, así como las distribuciones de sus valores.

Adicionalmente realiza un estudio similar al de los ejemplos 1.1 y 1.2

### Respuesta 1

#### Preprocesado de los datos

Los datos una vez importados, se realiza un preprocesado antes de continuar con el ejercicio. A continuación, se explica brevemente que significado tiene cada columna

1\. Month

2\. Day

3\. Year

4\. CaptureTime

5\. ReleaseTime

6\. BandNumber: código ID de cada halcón

7\. Species: CH=Cooper RT=Red-tailed SS=Sharp-Shinned

8\. Age: A=Adult or I=Imature

9\. Sex: F=Female or M=Male

10\. Wing: longitud en mm de las alas

11\. Weight: peso corporal en gramos

12\. Culmen: longitud en mm del pico

13\. Hallux: longitud en mm de las garras

14\. Tail: longitud en mm de la cola (medida de MacBride Raptor Center)

15\. StandardTail: longitud estándard de la cola en mm

16\. Tarsus: longitud en mm del hueso de la pata

17\. WingPitFat: cantidad de grasa en el wing pit

18\. KeelFat: cantidad de grasa en el chestbone

19\. Crop: cantidas de material en el crop (parecido al estómago)  1=full to 0=empty

#### Tipo de datos

Analizamos el tipo de datos y su estructura

```{r}

structure <- str(Hawks)
```

##### Limpieza

Ya se ha observado que existen valores vacíos, pero vamos a cuantificarlo.

```{r}

print('NA')
colSums(is.na(Hawks))
print('Blancos')
colSums(Hawks=="")
```

Tal y como se observa, si que existen campos vacíos y nulos. Concretamente encontramos valores nulos en Wing, Weight, Culman, Hallux, StandardTail, Tarsus, WingPitFat, KeelFat y Crop. En lo que respecta a valores en blanco, hay 576 valores en blanco en Sex.

En este caso, como los valores que encontramos en blanco son relativos al Sexo y esta variable no la consideramos para la clasificación de especies, no realizamos ninguna acción. En cuanto a los valores nulos, tampoco realizamos ninguna acción.

Por otro lado, seleccionaremos las columnas Wing, Weight, Culmen y Hallux para la clasificación. Ya que se considera que son los rasgos más importantes en la clasificación, además de ser las columnas con menores valores nulos en comparación con el resto de columnas.

```{r}

Hawks_grouped <- na.omit(Hawks[c("Wing", "Weight", "Culmen", "Hallux", "Species")])

head(Hawks_grouped, n=5)
```

```{r}

summary(Hawks_grouped)
```

En este punto, generamos un dataset con los datos de Wing y Weight para comprobar el desempeño del algoritmo k-means sabiendo que tenemos 3 clusters.

```{r}

Hawks_feat <- Hawks_grouped[c("Wing", "Weight")]
```

Para comenzar a realizar la agregación de k-means con datos autogenerados.

```{r}

if (!require('cluster')) install.packages('cluster')
library(cluster)
```

A continuación aplicamos el algoritmo k-means con 2, 3 y 4 clusters

```{r}

fit2       <- kmeans(Hawks_feat, 2)
y_cluster2 <- fit2$cluster

fit3       <- kmeans(Hawks_feat, 3)
y_cluster3 <- fit3$cluster

fit4       <- kmeans(Hawks_feat, 4)
y_cluster4 <- fit4$cluster
```

Empleamos la función clusplot para visualizar los clusters. Comenzando con 2 clusters

```{r}

clusplot(Hawks_feat, fit2$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Continuamos con 3.

```{r}
clusplot(Hawks_feat, fit3$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

Y finalizamos con 4.

```{r}

clusplot(Hawks_feat, fit4$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
```

A continuación se muestra el resultado si mostramos en diferente color las diferentes especies en función de Wing y Weight

```{r}
# Wing y Weight
plot(Hawks_grouped[c(1,2)], col=as.factor(Hawks_grouped$Species), main="Clasificación real Wing/Weight")
```

Como se puede comprobar, existen 3 clusters bien diferenciados que en el caso de realizar k-means donde k=3 apenas hay valores extremos.

Si comparamos el resultado tras aplicar kmeans con k=3, se obtiene lo siguiente.

```{r}
plot(Hawks_feat[c(1,2)], col=fit3$cluster, main="Clasificación k-means Wings y Weight")
```

Como se puede observar, la aproximación es clara y únicamente se obtienen fallos en aquellos valores donde algunos individuos se alejan de la región principal de cada clúster.

A continuación, se muestran las demás configuraciones comparando las diferentes variables donde se pueden identificar claramente 3 grupos.

```{r}
# Wing y Culmen
plot(Hawks_grouped[c(1,3)], col=as.factor(Hawks_grouped$Species), main="Clasificación real Wing/Culmen")
```

```{r}
# Wing y Hallux
plot(Hawks_grouped[c(1,4)], col=as.factor(Hawks_grouped$Species), main="Clasificación real Wing/Halllux")
```

```{r}
# Weight y Culmen
plot(Hawks_grouped[c(2,3)], col=as.factor(Hawks_grouped$Species), main="Clasificación real Weight/Culmen")
```

```{r}
# Weight y Hallux
plot(Hawks_grouped[c(2,4)], col=as.factor(Hawks_grouped$Species), main="Clasificación real Weight/Hallux")
```

```{r}
# Culmen y Hallux
plot(Hawks_grouped[c(3,4)], col=as.factor(Hawks_grouped$Species), main="Clasificación real Culmen/Hallux")
```

Ahora, podemos evaluar la calidad del proceso de agregación. Para lo que se puede usar la función silhouette, que calcula la silueta de cada muestra.

```{r}
d <- daisy(Hawks_feat)
sk2 <- silhouette(fit2$cluster, d)
sk3 <- silhouette(fit3$cluster, d)
sk4 <- silhouette(fit4$cluster, d)
```

La función silhouette devuelve para cada muestra el cluster donde ha sido asignado, el cluster vecino y el valor de la silueta tal y como se explica en el ejemplo 1.1. Calculando la media de la tercera columna será posible obtener una estimación de la calidad del agrupamiento.

```{r}

mean(sk2[,3])
```

```{r}
mean(sk3[,3])
```

```{r}
mean(sk4[,3])
```

En este caso, se observa como para k=2 se obtiene mejor resultado que para k=3.

Para continuar con el desarrollo del problema y en línea con el ejemplo 1.2, planteamos un ejemplo más realista en el que no se conoce el número óptimo de clústers y probamos con varios valores.

```{r}

Hawks_grouped_feat <- Hawks_grouped[c("Wing", "Weight", "Culmen", "Hallux")]
```

```{r}
d <- daisy(Hawks_grouped_feat) 
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(Hawks_grouped_feat, i)
  y_cluster     <- fit$cluster
  sk            <- silhouette(y_cluster, d)
  resultados[i] <- mean(sk[,3])
}
```

Se muestra en una gráfica los valores de las siluetas media de cada prueba para comprobar el número de clústers que mejor se adapta al conjunto de datos.

```{r}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="Silueta")
```

En este caso, donde se aprecia una mejora más significativa es para k=3.

Otra forma de evaluar el número optimo de clústers es considerando el que ofrece la menor suma de los cuadrados de las distancias de los puntos de cada grupo con respecto a su centro (withinss), con la mayor separación entre centros de grupos (betweenss). Se trata de una idea similar a la silueta, donde se aplica el método elbow, que consiste en la selección del número de clústers en base a la inspección de la gráfica que se obtiene al iterar con el mismo conjunto de datos para distintos valores del número de clústers. Se selecciona como número oóptimo el que se encuentra en el "codo" de la curva.

```{r}
resultados <- rep(0, 10)
for (i in c(2,3,4,5,6,7,8,9,10))
{
  fit           <- kmeans(Hawks_grouped_feat, i)
  resultados[i] <- fit$tot.withinss
}
plot(2:10,resultados[2:10],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="tot.tot.withinss")
```

En este caso el número óptimo son 5 que es cuando la curva comienza a estabilizarse.

Por otro lado se puede emplear la función kmeansrins del paquete fpc que ejecuta kmeans con un conjunto de valores para después seleccionar el valor del número de clústers que mejor funciona de acuerdo a los criterios de la silueta media ("aws") y Calinski-Harabasz("ch").

```{r}
if (!require('fpc')) install.packages('fpc')
library(fpc)
fit_ch  <- kmeansruns(Hawks_grouped_feat, krange = 1:10, criterion = "ch") 
fit_asw <- kmeansruns(Hawks_grouped_feat, krange = 1:10, criterion = "asw") 
```

Se comprueba el valor con el que se ha obtenido el mejor resultado y también se muestra el resultado para todos los valores de k con ambos criterios.

```{r}
fit_ch$bestk
```

```{r}
fit_asw$bestk
```

```{r}
plot(1:10,fit_ch$crit,type="o",col="blue",pch=0,xlab="Número de clústers",ylab="Criterio Calinski-Harabasz")
```

```{r}
plot(1:10,fit_asw$crit,type="o",col="blue",pch=0,xlab="Número de clústers",ylab="Criterio silueta media")
```

## Ejercicio 2

Con el juego de datos proporcionado realiza un estudio similar al del ejemplo 2

### Respuesta 2

En este ejerccicio, se trabajará con los algoritmos DBSCAN y OPTICS como métodos de clustering para la generación de grupos no radiales tal y como se hace en el ejemplo 2. Para ello se tomará como referencia las dimensiones Wing y Weight del dataset empleado en el anterior ejercicio.

```{r}
if (!require('dbscan')) install.packages('dbscan')
library(dbscan)
```

Se verá como su parámetro de entrada más relevante es minPts, que define la minima densidad aceptada alrededor de un centroide. Al incrementar este parámetro, se reduce el ruido que consiste en las observaciones no asignadas a ningún clúster.

En primer lugar, ordenadremos las observaciones de forma que los puntos más ceranos se conviertan en vecinos de ordenamiento, como una representación numérica del dendograma de una agrupación jerárquica.

```{r}
# Se lanza el algoritmo OPTICS con epsilon por defecto y fijando el criterio de vecindad en 10 al igual que en el ejemplo 2.
res <- optics(Hawks_feat, minPts = 10)
res
```

```{r}
# Obtenemos la ordenación de las observaciones o puntos
res$order
```

El próximo paso consiste en la generación de un diagrama de alcanzabilidad o reachability plot, en el que se aprecia de una forma visual la distancia de alcanzabilidad de cada punto.

Los valles representan clústers (cuanto más profundo es el valle, más denso es el clúster), mientras que las cimas indican los puntos que están entre las agrupaciones (estos puntos son candidatos a ser considerados outliers)

```{r}
# Gráfica de alcanzabilidad
plot(res)
```

Veamos otra representación del diagrama de alcanzabilidad, donde se observa las trazas de las distancias entre puntos cercanos del mismo clúster y entre los diferentes clústers.

```{r}
plot(Hawks_feat, col = "blue")
polygon(Hawks_feat[res$order,])
```

A continuación, realizaremos una agrupación de la ordenación realizada por OPTICS similar a lo que DBSCAN hubiera generado estableciento el parámetro epsilon en eps_cl=0.065. Además se probará estableciendolo en XXX y XXX para así observar su efecto.

```{r}
res1 <- extractDBSCAN(res, eps_cl = 25)
res1
```

```{r}
res2 <- extractDBSCAN(res, eps_cl = 50)
res2
```

```{r}
res3 <- extractDBSCAN(res, eps_cl = 15)
res3
```

```{r}
plot(res1)
```

```{r}
plot(res2)
```

```{r}
plot(res3)
```

Como se puede observar, si establecemos una epsilon muy baja, el algoritmo establece clústers donde no los hay debido a que a partir de ciertas distancias se colorean los diferentes clústers, aumentando el número de outliers. Por el contrario, con un epsilon de 50, se consigue representar los tres clústers del problema planteado correctamente, manteniendo un número mínimo de outliers.

Si continuamos con una representación gráfica, se muetra los clústers mediante formas convexas.

```{r}
hullplot(Hawks_feat, res2)
```

Si repetimos el anterior ejemplo con res1, donde epsilon era de 25, el número de clusters alcanzados es mayor.

```{r}
hullplot(Hawks_feat, res1)
```

A continuación veremos una variante de DBSCN donde se trabajará con el parámetro xi, que servirá apra clasificar clusters en función del cambio en la densidad relativa de los mismos.

```{r}
# Extracción del cluster jerarquico en función de la variación de la densidad por el método xi
resXi <- extractXi(res, xi=0.35)
resXi
```

```{r}
plot(resXi)
```

```{r}
hullplot(Hawks_feat, resXi)
```

Como se puede observar, los clusters obtenidos se ordenan de forma creciente dependiendo de la densidad y el tamaño de estos. Se observa como estos clusters van aumentando de tamaño hasta englobar el más pequeño.

## Ejercicio 3

Realiza una comparativa de los métodos *k-means* y *DBSCAN*

### Respuesta 3

Para realizar una comparación entre kmeans y DBSCAN partiremos de los resultados obtenidos en los anteriores ejercicios.

De esta forma, cuando empleamos kmeans la forma en la que se realiza el clústering, clasifican todos y cada uno de los puntos que forman parte de la muestra de datos tal y como se muestra a continuación.

```{r}
plot(Hawks_feat[c(1,2)], col=fit3$cluster, main="Clasificación k-means Wings y Weight")
```

A continuación se muestra el resultado obtenido empleando DBSCAN.

```{r}
hullplot(Hawks_feat, res2)
```

A continuación, introducimos los datos clasificados según su catalogación original.

```{r}
plot(Hawks_grouped[c(1,2)], col=as.factor(Hawks_grouped$Species), main="Clasificación real Wing/Weight")
```

Como puede observarse, los dos algoritmos obtienen resultados muy similares a la clasificación real. No obstante, se aprecian algunas diferencias entre ellos.

La primera y más evidente es que mientras con kmeans, se introducen todos los puntos en el clúster calculado, con DBSCAN, algunos de los puntos quedan fuera de ningún clúster y se catalogan como outliers, valores que no pertenecen a ningún cluster. Por otro lado, se debe mencionar que es posible ajustar esto último para que algún punto si que sea tenido en cuenta, sobre todo para el de color rojo. Considerando que los colores que tenemos en cuenta están referidos al caso real.

Por otro lado, cabe destacar que con kmeans, aunque no son muchos, se aprecian algunos de los valores incorrectos, sobre todo cuando el peso disminuye para aquellos pertenecientes al cluster rojo, ya que no estamos considerando que por ejemplo, una cría de ave, pueda tener un bajo peso, pero un mayor ala que el perteneciente al cluster verde. Es por ello, que con DBSCAN estos elementos alejados del grueso central de los datos no se tienen en cuenta y por lo tanto se evita un error no deseado.

Para terminar, se puede mencionar que en el caso de kmeans, se ha prefijado para un número de clusters de 3, mientras que con DBSCAN no ha sido necesario ya que solamente se ha fijado un valor de epsilon, lo cual puede considerarse como una desventaja. En el caso del problema presentado, ha sido necesario realizar una evaluación de kmeans y explorar diferentes valores de epsilon para obtener un buen resultado.

Como conclusiones, se puede afirmar que se ha estudiado el dataset con datos de halcones logrando un método de clustering de las diferentes especies con buenos resultados empleando diferentes métodos para ello. En este caso, el modelo que para mí puede ser más correcto utiliar es DBSCAN ya que kmeans tiene la posibilidad de sesgar el proceso de clustering por determinadas variables sin contar el contexto de los datos, para lo que un algoritmo basado en densidad consigue obviar aquellas situaciones fuera de lo común. No obstante, presenta limitaciones ya que no consigue catalogar todas las aves con su correspondiente cluster.

------------------------------------------------------------------------

# Criterios de evaluación

------------------------------------------------------------------------

## Ejercicio 1

-   10%. Se explican los campos de la base de datos\
-   25%. Se aplica el algoritmo de *k-means* de forma correcta.\
-   25%. Se prueban con diferentes valores de k.\
-   10%. Se obtiene una medida de lo bueno que es el agrupamiento.\
-   20%. Se describen e interpretan los diferentes clusters obtenidos.\
-   10%. Se presenta el código y es fácilmente reproducible.

## Ejercicio 2

-   20%. Se aplican lo algoritmos *DBSCAN* y *OPTICS* de forma correcta.\
-   25%. Se prueban con diferentes valores de eps.\
-   25%. Se obtiene una medida de lo bueno que es el agrupamiento.\
-   20%. Se describen e interpretan los diferentes clusters obtenidos.\
-   10%. Se presenta el código y es fácilmente reproducible.

## Ejercicio 3

-   35%. Se comparan los resultados obtenidos en *k-means* y *DBSCAN*.\
-   35%. Se mencionan pros y contras de ambos algoritmos\
-   30%. Se exponen la conclusiones del trabajo
